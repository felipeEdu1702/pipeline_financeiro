{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf6854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importação das Bibliotecas\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "\n",
    "# Opções pandas\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Configurações da conexão com o Postgres \n",
    "DB_USER = \"usuário do banco de dados\"\n",
    "DB_PASS = \"senha do banco de dados\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_NAME = \"nome do bando de dados\"\n",
    "\n",
    "def get_engine(user=DB_USER, pwd=DB_PASS, host=DB_HOST, db=DB_NAME):\n",
    "    return create_engine(f\"postgresql+psycopg2://{user}:{pwd}@{host}/{db}\")\n",
    "    \n",
    "  \n",
    "# Coleta a tabela de resultado do site Fundamentus e retorna o Dataframe bruto   \n",
    "def get_fundamentus_data():\n",
    "        \n",
    "        \n",
    "    url = \"http://www.fundamentus.com.br/resultado.php\"\n",
    "    headers = {\n",
    "        \"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                       \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                       \"Chrome/115.0 Safari/537.36\")\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers, timeout=30)\n",
    "    resp.encoding = \"latin1\"\n",
    "\n",
    "    tables = pd.read_html(resp.text, decimal=\",\", thousands=\".\")\n",
    "    if not tables:\n",
    "        raise ValueError(\"Nenhuma tabela encontrada no HTML do Fundamentus.\")\n",
    "    return tables[0] \n",
    "\n",
    "# testando a saída do Dataframe \n",
    "df_raw_fund = get_fundamentus_data()\n",
    "df_raw_fund.head()\n",
    "\n",
    "\n",
    "\n",
    "# Padronização dos Dados\n",
    "def clean_fundamentus_data(df):\n",
    "    \n",
    "    \n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower().replace(\" \", \"_\").replace(\"/\", \"_\") for c in df.columns]\n",
    "\n",
    "    # Garantir existência da coluna de ticker (costuma ser 'papel')\n",
    "    if \"papel\" in df.columns:\n",
    "        df.rename(columns={\"papel\": \"ticker\"}, inplace=True)\n",
    "\n",
    "    # Converter numéricos (ignora a primeira coluna assumida como ticker)\n",
    "    for col in df.columns:\n",
    "        if col == \"ticker\":\n",
    "            continue\n",
    "        try:\n",
    "            df[col] = (\n",
    "                df[col]\n",
    "                .astype(str)\n",
    "                .str.replace(\".\", \"\", regex=False)\n",
    "                .str.replace(\",\", \".\", regex=False)\n",
    "            )\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Ticker raiz (sem .SA) — para relacionar com Yahoo\n",
    "    if \"ticker\" in df.columns:\n",
    "        df[\"ticker_root\"] = df[\"ticker\"].astype(str).str.upper().str.strip()\n",
    "    else:\n",
    "        raise ValueError(\"Coluna de ticker não encontrada no Fundamentus.\")\n",
    "\n",
    "    # Timestamp de carga (bom pra auditoria)\n",
    "    df[\"dt_carga\"] = pd.Timestamp.utcnow()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Testando a saida do DataFrame \n",
    "df_fund = clean_fundamentus_data(df_raw_fund)\n",
    "df_fund.head()\n",
    "\n",
    "\n",
    "def save_to_postgres(df, tabela, if_exists=\"replace\"):\n",
    "    eng = get_engine()\n",
    "    df.to_sql(tabela, eng, if_exists=if_exists, index=False)\n",
    "    print(f\" Dados salvos na tabela '{tabela}' ({len(df)} linhas).\")\n",
    "    \n",
    "    \n",
    "def run_pipeline_fundamentus():\n",
    "    print(\" Fundamentus: iniciando...\")\n",
    "    df_raw = get_fundamentus_data()\n",
    "    print(\" Coleta ok.\")\n",
    "    df_clean = clean_fundamentus_data(df_raw)\n",
    "    print(\" Limpeza ok.\")\n",
    "    save_to_postgres(df_clean, \"acoes_info\", if_exists=\"replace\")\n",
    "    print(\" Fundamentus: concluído.\")\n",
    "    return df_clean\n",
    "\n",
    "# Execução do pipeline Fundamentus\n",
    "df_fund_final = run_pipeline_fundamentus()\n",
    "df_fund_final.head()\n",
    "\n",
    "\n",
    "# Coleta do histórico de preços do Yahoo Finance para uma lista de tickers .SA.\n",
    "# Retorna DataFrame consolidado e com colunas achatadas.\n",
    "\n",
    "def get_yahoo_data(tickers, start=\"2020-01-01\", end=None):\n",
    "        \n",
    "    \n",
    "    if end is None:\n",
    "        end = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    frames = []\n",
    "    for t in tickers:\n",
    "        try:\n",
    "            df = yf.download(t, start=start, end=end, progress=False)\n",
    "            if df.empty:\n",
    "                print(f\" Sem dados para {t}.\")\n",
    "                continue\n",
    "            df[\"ticker\"] = t\n",
    "            frames.append(df)\n",
    "            print(f\" Coletado {t} ({len(df)} linhas).\")\n",
    "        except Exception as e:\n",
    "            print(f\" Erro em {t}: {e}\")\n",
    "\n",
    "    if not frames:\n",
    "        raise ValueError(\"Nenhum dado coletado do Yahoo Finance.\")\n",
    "\n",
    "    out = pd.concat(frames).reset_index()\n",
    "\n",
    "    # Ajuste para evitar o erro das tuplas\n",
    "    if isinstance(out.columns, pd.MultiIndex):\n",
    "        out.columns = [\"_\".join([str(c) for c in col if c]) for col in out.columns]\n",
    "\n",
    "    return out\n",
    "\n",
    "# Testando a coleta feita no app Yahoo Finance\n",
    "tickers = [\"PETR4.SA\", \"VALE3.SA\", \"ITUB4.SA\"]\n",
    "df_yf_raw = get_yahoo_data(tickers)\n",
    "df_yf_raw.head()\n",
    "\n",
    "\n",
    "\n",
    " # Padroniza nomes e tipos; cria ticker_root para relacionamento.\n",
    "def clean_yahoo_data(df):\n",
    "        \n",
    "   \n",
    "    df = df.copy()\n",
    "    df.columns = [c.lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "    # Garantir tipos\n",
    "    if \"date\" in df.columns:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "    num_cols = [\"open\", \"high\", \"low\", \"close\", \"adj_close\", \"volume\"]\n",
    "    for c in num_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # ticker_root: remove .SA\n",
    "    if \"ticker\" in df.columns:\n",
    "        df[\"ticker_root\"] = df[\"ticker\"].astype(str).str.upper().str.replace(\".SA\", \"\", regex=False)\n",
    "    else:\n",
    "        raise ValueError(\"Coluna 'ticker' ausente no Yahoo.\")\n",
    "\n",
    "    df[\"dt_carga\"] = pd.Timestamp.utcnow()\n",
    "    return df\n",
    "\n",
    "\n",
    "# Função para testar a coleta do Yahoo Finance \n",
    "def run_pipeline_yahoo(tickers=None, start=\"2020-01-01\", end=None):\n",
    "    if tickers is None:\n",
    "        \n",
    "        # tickers .SA precisam existir — aqui vou usar 3 clássicos\n",
    "        tickers = [\"PETR4.SA\", \"VALE3.SA\", \"ITUB4.SA\"]\n",
    "\n",
    "    print(\" Yahoo: iniciando...\")\n",
    "    df_raw = get_yahoo_data(tickers, start=start, end=end)\n",
    "    print(\" Coleta ok.\")\n",
    "    df_clean = clean_yahoo_data(df_raw)\n",
    "    print(\" Limpeza ok.\")\n",
    "    save_to_postgres(df_clean, \"acoes_historico\", if_exists=\"replace\")\n",
    "    print(\" Yahoo: concluído.\")\n",
    "    return df_clean\n",
    "\n",
    "# Execução da função\n",
    "df_yf_final = run_pipeline_yahoo()\n",
    "df_yf_final.head()\n",
    "\n",
    "\n",
    "eng = get_engine()\n",
    "\n",
    "sql_check_1 = \"SELECT ticker, ticker_root, count(*) AS n FROM acoes_info GROUP BY 1,2 ORDER BY n DESC LIMIT 5;\"\n",
    "sql_check_2 = \"SELECT ticker, ticker_root, MIN(date) AS dt_min, MAX(date) AS dt_max, COUNT(*) AS n FROM acoes_historico GROUP BY 1,2 ORDER BY n DESC LIMIT 5;\"\n",
    "\n",
    "df_chk1 = pd.read_sql(sql_check_1, eng)\n",
    "df_chk2 = pd.read_sql(sql_check_2, eng)\n",
    "\n",
    "df_chk1, df_chk2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
